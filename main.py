import os
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
import google.generativeai as genai
from fastapi.responses import StreamingResponse # Thay v√¨ JSONResponse
import io # D√πng ƒë·ªÉ x·ª≠ l√Ω audio stream

# --- 1. IMPORT TH∆Ø VI·ªÜN AZURE ---
import azure.cognitiveservices.speech as speechsdk

# --- T·∫£i API keys ---
load_dotenv()

# C·∫•u h√¨nh Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise EnvironmentError("Ch∆∞a c√≥ GEMINI_API_KEY trong .env")
genai.configure(api_key=GEMINI_API_KEY)

# --- 2. C·∫§U H√åNH AZURE SPEECH ---
AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY")
AZURE_SPEECH_REGION = os.getenv("AZURE_SPEECH_REGION")

if not AZURE_SPEECH_KEY or not AZURE_SPEECH_REGION:
    raise EnvironmentError("Ch∆∞a c√≥ AZURE_SPEECH_KEY ho·∫∑c AZURE_SPEECH_REGION trong .env")

# C·∫•u h√¨nh gi·ªçng n√≥i
# speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)
# Ch·ªçn gi·ªçng n√≥i Ti·∫øng Vi·ªát chu·∫©n (N·ªØ mi·ªÅn Nam)
VIETNAMESE_VOICE = "vi-VN-HoaiMyNeural"
# B·∫°n c√≥ th·ªÉ ƒë·ªïi th√†nh Nam: "vi-VN-NamMinhNeural"

# ƒê·∫∑t ƒë·ªãnh d·∫°ng √¢m thanh ƒë·∫ßu ra l√† MP3
# speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3)


# --- 3. QU·∫¢N L√ù GEMs (Gi·ªØ nguy√™n) ---
CHARACTER_GEMS = {
    "1": { # üêª Boba Doll
        "model_name": "gemini-2.5-flash", 
        "system_instruction": """
B·∫°n l√† Boba Doll ‚Äì ch√∫ g·∫•u tr√† s·ªØa ƒë√°ng y√™u...
Quan tr·ªçng: B·∫°n PH·∫¢I LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát.
"""
    },
    "2": { # üê∞ Lumi Doll
        "model_name": "gemini-2.5-flash",
        "system_instruction": """
B·∫°n l√† Lumi Doll ‚Äì c√¥ th·ªè y√™u √°nh s√°ng...
Quan tr·ªçng: B·∫°n PH·∫¢I LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát.
"""
    },
    "3": { # üê± Mochi Doll
        "model_name": "gemini-2.5-flash",
        "system_instruction": """
B·∫°n l√† Mochi Doll ‚Äì m·ªôt c√¥ m√®o AI m·ªông m∆°...
Quan tr·ªçng: B·∫°n PH·∫¢I LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát.
"""
    },
    "4": { # üêï Shiba Doll
        "model_name": "gemini-2.5-flash",
        "system_instruction": """
B·∫°n l√† Shiba Doll ‚Äì ch√∫ ch√≥ Shiba tinh ngh·ªãch...
Quan tr·ªçng: B·∫°n PH·∫¢I LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát.
"""
    },
    "5": { # üêß Tapi Doll
        "model_name": "gemini-2.5-flash",
        "system_instruction": """
B·∫°n l√† Tapi Doll ‚Äì ch√∫ chim c√°nh c·ª•t nh·ªè...
Quan tr·ªçng: B·∫°n PH·∫¢I LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát.
"""
    },
    "default": {
        "model_name": "gemini-2.5-flash",
        "system_instruction": "B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch. Quan tr·ªçng: B·∫°n PH·∫¢I LU√îN LU√îN tr·∫£ l·ªùi b·∫±ng Ti·∫øng Vi·ªát."
    }
}

active_chat_sessions = {}

def get_chat_session(character_id: str):
    if character_id in active_chat_sessions:
        del active_chat_sessions[character_id] # X√≥a chat c≈© ƒë·ªÉ nh·∫≠n prompt m·ªõi

    config = CHARACTER_GEMS.get(character_id, CHARACTER_GEMS["default"])
    model = genai.GenerativeModel(
        model_name=config["model_name"],
        system_instruction=config["system_instruction"]
    )
    chat_session = model.start_chat()
    active_chat_sessions[character_id] = chat_session 
    print(f"ƒê√£ t·∫°o phi√™n chat m·ªõi (Ti·∫øng Vi·ªát) cho: {character_id}")
    return chat_session

# --- 4. H√ÄM T·ªîNG H·ª¢P √ÇM THANH (M·ªöI) ---
def synthesize_speech(text_to_speak):
    """
    H√†m n√†y g·ªçi Azure, bi·∫øn Text th√†nh Audio (d·∫°ng bytes)
    """
    # C·∫•u h√¨nh Azure TTS
    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_SPEECH_REGION)
    speech_config.speech_synthesis_voice_name = VIETNAMESE_VOICE
    speech_config.set_speech_synthesis_output_format(speechsdk.SpeechSynthesisOutputFormat.Audio16Khz32KBitRateMonoMp3)
    
    # S·ª≠ d·ª•ng PullAudioOutputStream ƒë·ªÉ l·∫•y k·∫øt qu·∫£ d·∫°ng in-memory
    pull_stream = speechsdk.audio.PullAudioOutputStream()
    
    # C·∫•u h√¨nh synthesizer
    stream_config = speechsdk.audio.AudioOutputConfig(stream=pull_stream)
    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=stream_config)

    # B·∫Øt ƒë·∫ßu t·ªïng h·ª£p
    result = speech_synthesizer.speak_text_async(text_to_speak).get()

    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        print("T·ªïng h·ª£p √¢m thanh th√†nh c√¥ng.")
        # L·∫•y d·ªØ li·ªáu audio t·ª´ stream
        audio_data = result.audio_data
        return audio_data
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation = result.cancellation_details
        print(f"L·ªói t·ªïng h·ª£p √¢m thanh: {cancellation.reason}")
        if cancellation.reason == speechsdk.CancellationReason.Error:
            print(f"Chi ti·∫øt l·ªói: {cancellation.error_details}")
        raise HTTPException(status_code=500, detail="L·ªói khi t·ªïng h·ª£p gi·ªçng n√≥i t·ª´ Azure")

# --- 5. KH·ªûI T·∫†O APP V√Ä API ENDPOINT (C·∫¨P NH·∫¨T) ---

app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"], 
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

class ChatRequest(BaseModel):
    text: str
    character_id: str

@app.post("/api/chat")
async def chat(request: ChatRequest):
    try:
        print(f"User (to {request.character_id}) > {request.text}")

        # B∆∞·ªõc A: L·∫•y text t·ª´ Gemini
        session = get_chat_session(request.character_id)
        response = session.send_message(request.text)
        ai_text = response.text
        print(f"Gemini ({request.character_id}) > {ai_text}")

        # B∆∞·ªõc B: L·∫•y text ƒë√≥ v√† chuy·ªÉn th√†nh Audio (MP3)
        audio_bytes = synthesize_speech(ai_text)
        
        # B∆∞·ªõc C: Tr·∫£ v·ªÅ file MP3 cho frontend
        # D√πng StreamingResponse ƒë·ªÉ g·ª≠i d·ªØ li·ªáu audio
        return StreamingResponse(io.BytesIO(audio_bytes), media_type="audio/mpeg")

    except Exception as e:
        print(f"Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    print("Starting Backend server (Azure TTS Enabled) at http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)